{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d3b149-8b5c-48fa-a1e9-14d045676c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"/miniconda3/include/opencv4\")\n",
    "#pragma cling add_include_path(\"/miniconda3/include\")\n",
    "#pragma cling add_library_path(\"/miniconda3/lib\")\n",
    "#pragma cling load(\"vart-runner\")\n",
    "#pragma cling load(\"opencv_videoio\")\n",
    "#pragma cling load(\"opencv_imgcodecs\")\n",
    "#pragma cling load(\"opencv_highgui\")\n",
    "#pragma cling load(\"opencv_imgproc\")\n",
    "#pragma cling load(\"opencv_core\")\n",
    "#pragma cling load(\"glog\")\n",
    "#pragma cling load(\"xir\")\n",
    "#pragma cling load(\"unilog\")\n",
    "#pragma cling load(\"pthread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf33b81-43f9-47ea-a5fb-fba87ad8fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <dirent.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <sys/stat.h>\n",
    "#include <unistd.h>\n",
    "#include <cmath>\n",
    "#include <cstdio>\n",
    "#include <fstream>\n",
    "#include <iomanip>\n",
    "#include <iostream>\n",
    "#include <queue>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <numeric>\n",
    "#include <glog/logging.h>\n",
    "#include <mutex>\n",
    "#include <vart/mm/host_flat_tensor_buffer.hpp>\n",
    "#include <vart/runner.hpp>\n",
    "#include <xir/graph/graph.hpp>\n",
    "#include <xir/tensor/tensor.hpp>\n",
    "#include <xir/util/data_type.hpp>\n",
    "\n",
    "#include \"common.h\"\n",
    "#include <opencv2/opencv.hpp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db009eaa-8aa9-42a9-ae09-a2ca7abb1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace std;\n",
    "using namespace cv;\n",
    "\n",
    "const string baseImagePath = \"./img/\";\n",
    "const string wordsPath = \"./img/\";\n",
    "\n",
    "GraphInfo shapes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fda16a7-aa1a-440f-81fa-65d6012da67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * @brief put image names to a vector\n",
    " *\n",
    " * @param path - path of the image direcotry\n",
    " * @param images - the vector of image name\n",
    " *\n",
    " * @return none\n",
    " */\n",
    "void ListImages(string const& path, vector<string>& images) {\n",
    "  images.clear();\n",
    "  struct dirent* entry;\n",
    "\n",
    "  /*Check if path is a valid directory path. */\n",
    "  struct stat s;\n",
    "  lstat(path.c_str(), &s);\n",
    "  if (!S_ISDIR(s.st_mode)) {\n",
    "    fprintf(stderr, \"Error: %s is not a valid directory!\\n\", path.c_str());\n",
    "    exit(1);\n",
    "  }\n",
    "\n",
    "  DIR* dir = opendir(path.c_str());\n",
    "  if (dir == nullptr) {\n",
    "    fprintf(stderr, \"Error: Open %s path failed.\\n\", path.c_str());\n",
    "    exit(1);\n",
    "  }\n",
    "\n",
    "  while ((entry = readdir(dir)) != nullptr) {\n",
    "    if (entry->d_type == DT_REG || entry->d_type == DT_UNKNOWN) {\n",
    "      string name = entry->d_name;\n",
    "      string ext = name.substr(name.find_last_of(\".\") + 1);\n",
    "      if ((ext == \"JPEG\") || (ext == \"jpeg\") || (ext == \"JPG\") ||\n",
    "          (ext == \"jpg\") || (ext == \"PNG\") || (ext == \"png\")) {\n",
    "        images.push_back(name);\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  closedir(dir);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e9a32c-7666-4661-82df-8e4e1262c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * @brief load kinds from file to a vector\n",
    " *\n",
    " * @param path - path of the kinds file\n",
    " * @param kinds - the vector of kinds string\n",
    " *\n",
    " * @return none\n",
    " */\n",
    "void LoadWords(string const& path, vector<string>& kinds) {\n",
    "  kinds.clear();\n",
    "  ifstream fkinds(path);\n",
    "  if (fkinds.fail()) {\n",
    "    fprintf(stderr, \"Error : Open %s failed.\\n\", path.c_str());\n",
    "    exit(1);\n",
    "  }\n",
    "  string kind;\n",
    "  while (getline(fkinds, kind)) {\n",
    "    kinds.push_back(kind);\n",
    "  }\n",
    "\n",
    "  fkinds.close();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82202171-e280-45f6-8241-65976ce040eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * @brief calculate softmax\n",
    " *\n",
    " * @param data - pointer to input buffer\n",
    " * @param size - size of input buffer\n",
    " * @param result - calculation result\n",
    " *\n",
    " * @return none\n",
    " */\n",
    "void CPUCalcSoftmax(const float* data, size_t size, float* result) {\n",
    "  assert(data && result);\n",
    "  double sum = 0.0f;\n",
    "\n",
    "  for (size_t i = 0; i < size; i++) {\n",
    "    result[i] = exp(data[i]);\n",
    "    sum += result[i];\n",
    "  }\n",
    "  for (size_t i = 0; i < size; i++) {\n",
    "    result[i] /= sum;\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411a72da-f591-4a25-8e73-a2ac7691a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * @brief Get top k results according to its probability\n",
    " *\n",
    " * @param d - pointer to input data\n",
    " * @param size - size of input data\n",
    " * @param k - calculation result\n",
    " * @param vkinds - vector of kinds\n",
    " *\n",
    " * @return none\n",
    " */\n",
    "void TopK(const float* d, int size, int k, vector<string>& vkinds) {\n",
    "  assert(d && size > 0 && k > 0);\n",
    "  priority_queue<pair<float, int>> q;\n",
    "\n",
    "  for (auto i = 0; i < size; ++i) {\n",
    "    q.push(pair<float, int>(d[i], i));\n",
    "  }\n",
    "\n",
    "  for (auto i = 0; i < k; ++i) {\n",
    "    pair<float, int> ki = q.top();\n",
    "    printf(\"top[%d] prob = %-8f  name = %s\\n\", i, d[ki.second],\n",
    "           vkinds[ki.second].c_str());\n",
    "    q.pop();\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d099cf-05c3-4bfd-820f-66ac5ee8a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * @brief Run DPU Task for ResNet50\n",
    " *\n",
    " * @param taskResnet50 - pointer to ResNet50 Task\n",
    " *\n",
    " * @return none\n",
    " */\n",
    "void runResnet50(vart::Runner* runner) {\n",
    "  /* Mean value for ResNet50 specified in Caffe prototxt */\n",
    "  vector<std::string> kinds, images;\n",
    "\n",
    "  /* Load all image names.*/\n",
    "  ListImages(baseImagePath, images);\n",
    "  if (images.size() == 0) {\n",
    "    //std::cerr << \"\\nError: No images existing under \" << baseImagePath << endl;\n",
    "    return;\n",
    "  }\n",
    "\n",
    "  /* Load all kinds words.*/\n",
    "  LoadWords(wordsPath + \"words.txt\", kinds);\n",
    "  if (kinds.size() == 0) {\n",
    "    //std::cerr << \"\\nError: No words exist in file words.txt.\" << endl;\n",
    "    return;\n",
    "  }\n",
    "  float mean[3] = {104, 107, 123};\n",
    "\n",
    "  /* get in/out tensors and dims*/\n",
    "  auto outputTensors = runner->get_output_tensors();\n",
    "  auto inputTensors = runner->get_input_tensors();\n",
    "  auto out_dims = outputTensors[0]->get_shape();\n",
    "  auto in_dims = inputTensors[0]->get_shape();\n",
    "\n",
    "  /*get shape info*/\n",
    "  int outSize = shapes.outTensorList[0].size;\n",
    "  int inSize = shapes.inTensorList[0].size;\n",
    "  int inHeight = shapes.inTensorList[0].height;\n",
    "  int inWidth = shapes.inTensorList[0].width;\n",
    "\n",
    "  int batchSize = in_dims[0];\n",
    "\n",
    "  std::vector<std::unique_ptr<vart::TensorBuffer>> inputs, outputs;\n",
    "\n",
    "  vector<cv::Mat> imageList;\n",
    "  float* imageInputs = new float[inSize * batchSize];\n",
    "\n",
    "  float* softmax = new float[outSize];\n",
    "  float* FCResult = new float[batchSize * outSize];\n",
    "  std::vector<vart::TensorBuffer*> inputsPtr, outputsPtr;\n",
    "  std::vector<std::shared_ptr<xir::Tensor>> batchTensors;\n",
    "  /*run with batch*/\n",
    "  for (unsigned int n = 0; n < images.size(); n += batchSize) {\n",
    "    unsigned int runSize =\n",
    "        (images.size() < (n + batchSize)) ? (images.size() - n) : batchSize;\n",
    "    in_dims[0] = runSize;\n",
    "    out_dims[0] = batchSize;\n",
    "    for (unsigned int i = 0; i < runSize; i++) {\n",
    "      cv::Mat image = cv::imread(baseImagePath + images[n + i]);\n",
    "\n",
    "      /*image pre-process*/\n",
    "      cv::Mat image2 = cv::Mat(inHeight, inWidth, CV_8SC3);\n",
    "      resize(image, image2, cv::Size(inHeight, inWidth), 0, 0, cv::INTER_NEAREST);\n",
    "      for (int h = 0; h < inHeight; h++) {\n",
    "        for (int w = 0; w < inWidth; w++) {\n",
    "          for (int c = 0; c < 3; c++) {\n",
    "            imageInputs[i * inSize + h * inWidth * 3 + w * 3 + c] =\n",
    "                image2.at<cv::Vec3b>(h, w)[c] - mean[c];\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      imageList.push_back(image);\n",
    "    }\n",
    "\n",
    "    /* in/out tensor refactory for batch inout/output */\n",
    "    batchTensors.push_back(std::shared_ptr<xir::Tensor>(xir::Tensor::create(\n",
    "        inputTensors[0]->get_name(), in_dims,\n",
    "        xir::DataType{xir::DataType::FLOAT, sizeof(float) * 8u})));\n",
    "    inputs.push_back(std::make_unique<CpuFlatTensorBuffer>(\n",
    "        imageInputs, batchTensors.back().get()));\n",
    "    batchTensors.push_back(std::shared_ptr<xir::Tensor>(xir::Tensor::create(\n",
    "        outputTensors[0]->get_name(), out_dims,\n",
    "        xir::DataType{xir::DataType::FLOAT, sizeof(float) * 8u})));\n",
    "    outputs.push_back(std::make_unique<CpuFlatTensorBuffer>(\n",
    "        FCResult, batchTensors.back().get()));\n",
    "\n",
    "    /*tensor buffer input/output */\n",
    "    inputsPtr.clear();\n",
    "    outputsPtr.clear();\n",
    "    inputsPtr.push_back(inputs[0].get());\n",
    "    outputsPtr.push_back(outputs[0].get());\n",
    "\n",
    "    /*run*/\n",
    "    auto job_id = runner->execute_async(inputsPtr, outputsPtr);\n",
    "    runner->wait(job_id.first, -1);\n",
    "    for (unsigned int i = 0; i < runSize; i++) {\n",
    "      cout << \"\\nImage : \" << images[n + i] << endl;\n",
    "      /* Calculate softmax on CPU and display TOP-5 classification results */\n",
    "      CPUCalcSoftmax(&FCResult[i * outSize], outSize, softmax);\n",
    "      TopK(softmax, outSize, 5, kinds);\n",
    "      /* Display the impage */\n",
    "      cv::imshow(\"Classification of ResNet50\", imageList[i]);\n",
    "      cv::waitKey(10000);\n",
    "    }\n",
    "    imageList.clear();\n",
    "    inputs.clear();\n",
    "    outputs.clear();\n",
    "  }\n",
    "  delete[] FCResult;\n",
    "  delete[] imageInputs;\n",
    "  delete[] softmax;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cdd8f33-5ff1-4c76-985d-38a693dfa11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "int getTensorShape(vart::Runner* runner, GraphInfo* shapes, int cntin,\n",
    "                   int cntout) {\n",
    "  auto outputTensors = runner->get_output_tensors();\n",
    "  auto inputTensors = runner->get_input_tensors();\n",
    "  if (shapes->output_mapping.empty()) {\n",
    "    shapes->output_mapping.resize((unsigned)cntout);\n",
    "    std::iota(shapes->output_mapping.begin(), shapes->output_mapping.end(), 0);\n",
    "  }\n",
    "  for (int i = 0; i < cntin; i++) {\n",
    "    auto dim_num = inputTensors[i]->get_shape().size();\n",
    "    if (dim_num == 4) {\n",
    "      shapes->inTensorList[i].channel = inputTensors[i]->get_shape().at(3);\n",
    "      shapes->inTensorList[i].width = inputTensors[i]->get_shape().at(2);\n",
    "      shapes->inTensorList[i].height = inputTensors[i]->get_shape().at(1);\n",
    "      shapes->inTensorList[i].size =\n",
    "          inputTensors[i]->get_element_num() / inputTensors[0]->get_shape().at(0);\n",
    "    } else if (dim_num == 2) {\n",
    "      shapes->inTensorList[i].channel = inputTensors[i]->get_shape().at(1);\n",
    "      shapes->inTensorList[i].width = 1;\n",
    "      shapes->inTensorList[i].height = 1;\n",
    "      shapes->inTensorList[i].size =\n",
    "          inputTensors[i]->get_element_num() / inputTensors[0]->get_shape().at(0);\n",
    "    }\n",
    "  }\n",
    "  for (int i = 0; i < cntout; i++) {\n",
    "    auto dim_num = outputTensors[shapes->output_mapping[i]]->get_shape().size();\n",
    "    if (dim_num == 4) {\n",
    "      shapes->outTensorList[i].channel =\n",
    "          outputTensors[shapes->output_mapping[i]]->get_shape().at(3);\n",
    "      shapes->outTensorList[i].width =\n",
    "          outputTensors[shapes->output_mapping[i]]->get_shape().at(2);\n",
    "      shapes->outTensorList[i].height =\n",
    "          outputTensors[shapes->output_mapping[i]]->get_shape().at(1);\n",
    "      shapes->outTensorList[i].size =\n",
    "          outputTensors[shapes->output_mapping[i]]->get_element_num() /\n",
    "          outputTensors[shapes->output_mapping[0]]->get_shape().at(0);\n",
    "    } else if (dim_num == 2) {\n",
    "      shapes->outTensorList[i].channel =\n",
    "          outputTensors[shapes->output_mapping[i]]->get_shape().at(1);\n",
    "      shapes->outTensorList[i].width = 1;\n",
    "      shapes->outTensorList[i].height = 1;\n",
    "      shapes->outTensorList[i].size =\n",
    "          outputTensors[shapes->output_mapping[i]]->get_element_num() /\n",
    "          outputTensors[shapes->output_mapping[0]]->get_shape().at(0);\n",
    "    }\n",
    "  }\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e375af82-5869-4605-b238-7eb785b4c262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1minput_line_18:3:42: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1mno member named 'get' in 'std::unique_ptr<xir::Graph, std::default_delete<xir::Graph> >'\u001b[0m\n",
      "  auto subgraph = get_dpu_subgraph(graph.get());\n",
      "\u001b[0;1;32m                                   ~~~~~ ^\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "Interpreter Error",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Interpreter Error: "
     ]
    }
   ],
   "source": [
    "void run_test(){ \n",
    "  auto graph = xir::Graph::deserialize(\"dpu_resnet50.xmodel\");\n",
    "  auto subgraph = get_dpu_subgraph(graph.get());\n",
    "  CHECK_EQ(subgraph.size(), 1u)\n",
    "      << \"resnet50 should have one and only one dpu subgraph.\";\n",
    "  LOG(INFO) << \"create running for subgraph: \" << subgraph[0]->get_name();\n",
    "  /*create runner*/\n",
    "  auto runner = vart::Runner::create_runner(subgraph[0], \"run\");\n",
    "  // ai::XdpuRunner* runner = new ai::XdpuRunner(\"./\");\n",
    "  /*get in/out tensor*/\n",
    "  auto inputTensors = runner->get_input_tensors();\n",
    "  auto outputTensors = runner->get_output_tensors();\n",
    "\n",
    "  /*get in/out tensor shape*/\n",
    "  int inputCnt = inputTensors.size();\n",
    "  int outputCnt = outputTensors.size();\n",
    "  TensorShape inshapes[inputCnt];\n",
    "  TensorShape outshapes[outputCnt];\n",
    "  shapes.inTensorList = inshapes;\n",
    "  shapes.outTensorList = outshapes;\n",
    "  getTensorShape(runner.get(), &shapes, inputCnt, outputCnt);\n",
    "\n",
    "  /*run with batch*/\n",
    "  runResnet50(runner.get());\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
